import faiss
import numpy as np
import pickle
import json
import os
import time
from typing import List, Tuple, Dict

class FAISSIndexManager:
    """
    Quáº£n lÃ½ FAISS index cho image retrieval
    """
    def __init__(self, feature_dim: int):
        """
        Args:
            feature_dim: Sá»‘ chiá»u cá»§a feature vector
        """
        self.feature_dim = feature_dim
        self.index = None
        self.index_type = None
        
    def create_flat_index(self, features: np.ndarray, use_gpu: bool = False):
        """
        Táº¡o Flat index (exact search) - TÃ¬m kiáº¿m chÃ­nh xÃ¡c
        
        Args:
            features: Feature vectors [N, D]
            use_gpu: CÃ³ sá»­ dá»¥ng GPU khÃ´ng
            
        Returns:
            FAISS index
        """
        print(f"\nğŸ”¨ Äang táº¡o IndexFlatL2...")
        print(f"   - Feature dimension: {self.feature_dim}")
        print(f"   - Number of vectors: {len(features)}")
        print(f"   - Use GPU: {use_gpu}")
        
        # Táº¡o index
        index = faiss.IndexFlatL2(self.feature_dim)
        
        # Chuyá»ƒn sang GPU náº¿u cáº§n
        if use_gpu and faiss.get_num_gpus() > 0:
            print(f"   - Chuyá»ƒn index sang GPU...")
            res = faiss.StandardGpuResources()
            index = faiss.index_cpu_to_gpu(res, 0, index)
        
        # ThÃªm vectors vÃ o index
        start_time = time.time()
        index.add(features.astype(np.float32))
        elapsed = time.time() - start_time
        
        print(f"   âœ… HoÃ n thÃ nh trong {elapsed:.2f}s")
        print(f"   - Total vectors in index: {index.ntotal}")
        
        self.index = index
        self.index_type = "IndexFlatL2"
        return index
    
    def create_ivf_index(self, features: np.ndarray, 
                        nlist: int = 100, 
                        nprobe: int = 10,
                        use_gpu: bool = False):
        """
        Táº¡o IVF index (approximate search) - TÃ¬m kiáº¿m xáº¥p xá»‰ nhanh hÆ¡n
        
        Args:
            features: Feature vectors [N, D]
            nlist: Sá»‘ lÆ°á»£ng clusters (cÃ ng lá»›n cÃ ng chÃ­nh xÃ¡c nhÆ°ng cháº­m hÆ¡n)
            nprobe: Sá»‘ clusters tÃ¬m kiáº¿m (cÃ ng lá»›n cÃ ng chÃ­nh xÃ¡c nhÆ°ng cháº­m hÆ¡n)
            use_gpu: CÃ³ sá»­ dá»¥ng GPU khÃ´ng
            
        Returns:
            FAISS index
        """
        print(f"\nğŸ”¨ Äang táº¡o IndexIVFFlat...")
        print(f"   - Feature dimension: {self.feature_dim}")
        print(f"   - Number of vectors: {len(features)}")
        print(f"   - nlist (clusters): {nlist}")
        print(f"   - nprobe (search): {nprobe}")
        print(f"   - Use GPU: {use_gpu}")
        
        # Táº¡o quantizer
        quantizer = faiss.IndexFlatL2(self.feature_dim)
        
        # Táº¡o IVF index
        index = faiss.IndexIVFFlat(quantizer, self.feature_dim, nlist)
        
        # Chuyá»ƒn sang GPU náº¿u cáº§n
        if use_gpu and faiss.get_num_gpus() > 0:
            print(f"   - Chuyá»ƒn index sang GPU...")
            res = faiss.StandardGpuResources()
            index = faiss.index_cpu_to_gpu(res, 0, index)
        
        # Train index vá»›i má»™t pháº§n dá»¯ liá»‡u
        print(f"   - Training index...")
        start_time = time.time()
        
        # Sample data cho training náº¿u quÃ¡ lá»›n
        train_size = min(len(features), 10000)
        train_data = features[:train_size].astype(np.float32)
        index.train(train_data)
        
        train_time = time.time() - start_time
        print(f"   âœ… Training hoÃ n thÃ nh trong {train_time:.2f}s")
        
        # ThÃªm vectors vÃ o index
        print(f"   - Adding vectors to index...")
        start_time = time.time()
        index.add(features.astype(np.float32))
        add_time = time.time() - start_time
        
        # Set nprobe
        index.nprobe = nprobe
        
        print(f"   âœ… HoÃ n thÃ nh trong {add_time:.2f}s")
        print(f"   - Total vectors in index: {index.ntotal}")
        
        self.index = index
        self.index_type = f"IndexIVFFlat_nlist{nlist}_nprobe{nprobe}"
        return index
    
    def create_hnsw_index(self, features: np.ndarray, 
                         M: int = 32, 
                         efConstruction: int = 200,
                         efSearch: int = 64):
        """
        Táº¡o HNSW index (Hierarchical Navigable Small World) - Ráº¥t nhanh vÃ  chÃ­nh xÃ¡c
        
        Args:
            features: Feature vectors [N, D]
            M: Sá»‘ lÆ°á»£ng káº¿t ná»‘i trÃªn má»—i layer (16-64, máº·c Ä‘á»‹nh 32)
            efConstruction: Äá»™ rá»™ng tÃ¬m kiáº¿m khi xÃ¢y dá»±ng (100-500)
            efSearch: Äá»™ rá»™ng tÃ¬m kiáº¿m khi query (10-500)
            
        Returns:
            FAISS index
        """
        print(f"\nğŸ”¨ Äang táº¡o IndexHNSWFlat...")
        print(f"   - Feature dimension: {self.feature_dim}")
        print(f"   - Number of vectors: {len(features)}")
        print(f"   - M: {M}")
        print(f"   - efConstruction: {efConstruction}")
        print(f"   - efSearch: {efSearch}")
        
        # Táº¡o HNSW index
        index = faiss.IndexHNSWFlat(self.feature_dim, M)
        index.hnsw.efConstruction = efConstruction
        index.hnsw.efSearch = efSearch
        
        # ThÃªm vectors
        print(f"   - Adding vectors...")
        start_time = time.time()
        index.add(features.astype(np.float32))
        elapsed = time.time() - start_time
        
        print(f"   âœ… HoÃ n thÃ nh trong {elapsed:.2f}s")
        print(f"   - Total vectors in index: {index.ntotal}")
        
        self.index = index
        self.index_type = f"IndexHNSWFlat_M{M}_ef{efSearch}"
        return index
    
    def search(self, query_vector: np.ndarray, k: int = 10) -> Tuple[np.ndarray, np.ndarray]:
        """
        TÃ¬m kiáº¿m k vectors gáº§n nháº¥t
        
        Args:
            query_vector: Query vector [1, D] hoáº·c [D]
            k: Sá»‘ lÆ°á»£ng káº¿t quáº£ tráº£ vá»
            
        Returns:
            distances, indices: Khoáº£ng cÃ¡ch vÃ  indices cá»§a k vectors gáº§n nháº¥t
        """
        if self.index is None:
            raise ValueError("Index chÆ°a Ä‘Æ°á»£c táº¡o!")
        
        # Reshape query vector náº¿u cáº§n
        if query_vector.ndim == 1:
            query_vector = query_vector.reshape(1, -1)
        
        query_vector = query_vector.astype(np.float32)
        
        # Search
        distances, indices = self.index.search(query_vector, k)
        
        return distances[0], indices[0]
    
    def save_index(self, filepath: str):
        """
        LÆ°u FAISS index ra file
        
        Args:
            filepath: ÄÆ°á»ng dáº«n file .index
        """
        if self.index is None:
            raise ValueError("Index chÆ°a Ä‘Æ°á»£c táº¡o!")
        
        # Convert GPU index vá» CPU trÆ°á»›c khi lÆ°u
        if hasattr(self.index, 'index'):  # GPU index
            cpu_index = faiss.index_gpu_to_cpu(self.index)
        else:
            cpu_index = self.index
        
        faiss.write_index(cpu_index, filepath)
        print(f"ğŸ’¾ ÄÃ£ lÆ°u index vÃ o: {filepath}")
    
    def load_index(self, filepath: str, use_gpu: bool = False):
        """
        Load FAISS index tá»« file
        
        Args:
            filepath: ÄÆ°á»ng dáº«n file .index
            use_gpu: CÃ³ chuyá»ƒn lÃªn GPU khÃ´ng
        """
        print(f"ğŸ“‚ Äang load index tá»«: {filepath}")
        index = faiss.read_index(filepath)
        
        if use_gpu and faiss.get_num_gpus() > 0:
            print(f"   - Chuyá»ƒn index sang GPU...")
            res = faiss.StandardGpuResources()
            index = faiss.index_cpu_to_gpu(res, 0, index)
        
        self.index = index
        print(f"   âœ… ÄÃ£ load {index.ntotal} vectors")
        
        return index

def build_faiss_indexes(features_dir: str = './features',
                       output_dir: str = './faiss_indexes',
                       build_all: bool = True):
    """
    XÃ¢y dá»±ng cÃ¡c FAISS indexes
    
    Args:
        features_dir: ThÆ° má»¥c chá»©a features
        output_dir: ThÆ° má»¥c lÆ°u indexes
        build_all: XÃ¢y dá»±ng táº¥t cáº£ loáº¡i index
    """
    print("=" * 70)
    print("ğŸ—ï¸  XÃ‚Y Dá»°NG FAISS INDEXES")
    print("=" * 70)
    
    # 1. Load features
    print("\nğŸ“‚ Äang load features...")
    features_file = os.path.join(features_dir, 'features.npy')
    metadata_file = os.path.join(features_dir, 'features_metadata.json')
    
    features = np.load(features_file)
    with open(metadata_file, 'r') as f:
        metadata = json.load(f)
    
    print(f"   âœ… ÄÃ£ load features")
    print(f"   - Shape: {features.shape}")
    print(f"   - Feature dim: {metadata['feature_dim']}")
    print(f"   - Total vectors: {len(features)}")
    
    # 2. Táº¡o output directory
    os.makedirs(output_dir, exist_ok=True)
    
    # 3. Khá»Ÿi táº¡o manager
    manager = FAISSIndexManager(feature_dim=metadata['feature_dim'])
    
    # 4. Táº¡o cÃ¡c loáº¡i index
    indexes_info = []
    
    # 4.1. IndexFlatL2 (Exact Search)
    print("\n" + "=" * 70)
    print("1ï¸âƒ£  INDEXFLATL2 - EXACT SEARCH")
    print("=" * 70)
    manager.create_flat_index(features, use_gpu=False)
    
    flat_index_file = os.path.join(output_dir, 'index_flat_l2.index')
    manager.save_index(flat_index_file)
    
    indexes_info.append({
        'type': 'IndexFlatL2',
        'file': flat_index_file,
        'description': 'Exact search - chÃ­nh xÃ¡c 100% nhÆ°ng cháº­m vá»›i dá»¯ liá»‡u lá»›n',
        'speed': 'Slow',
        'accuracy': '100%',
        'recommended_for': 'Dataset nhá» (<100K vectors)'
    })
    
    if build_all:
        # 4.2. IndexIVFFlat (Approximate Search)
        print("\n" + "=" * 70)
        print("2ï¸âƒ£  INDEXIVFFLAT - APPROXIMATE SEARCH")
        print("=" * 70)
        
        # TÃ­nh nlist dá»±a trÃªn sá»‘ lÆ°á»£ng vectors
        n_vectors = len(features)
        nlist = min(int(np.sqrt(n_vectors)), 1000)  # Rule of thumb
        nprobe = max(int(nlist * 0.1), 10)  # 10% cá»§a nlist
        
        manager.create_ivf_index(features, nlist=nlist, nprobe=nprobe, use_gpu=False)
        
        ivf_index_file = os.path.join(output_dir, 'index_ivf_flat.index')
        manager.save_index(ivf_index_file)
        
        indexes_info.append({
            'type': 'IndexIVFFlat',
            'file': ivf_index_file,
            'nlist': nlist,
            'nprobe': nprobe,
            'description': 'Approximate search - nhanh hÆ¡n, Ä‘á»™ chÃ­nh xÃ¡c ~95%',
            'speed': 'Medium-Fast',
            'accuracy': '~95%',
            'recommended_for': 'Dataset trung bÃ¬nh (100K-1M vectors)'
        })
        
        # 4.3. IndexHNSWFlat (Fast & Accurate)
        print("\n" + "=" * 70)
        print("3ï¸âƒ£  INDEXHNSWFLAT - FAST & ACCURATE")
        print("=" * 70)
        manager.create_hnsw_index(features, M=32, efConstruction=200, efSearch=64)
        
        hnsw_index_file = os.path.join(output_dir, 'index_hnsw_flat.index')
        manager.save_index(hnsw_index_file)
        
        indexes_info.append({
            'type': 'IndexHNSWFlat',
            'file': hnsw_index_file,
            'M': 32,
            'efSearch': 64,
            'description': 'Hierarchical NSW - ráº¥t nhanh vÃ  chÃ­nh xÃ¡c ~99%',
            'speed': 'Very Fast',
            'accuracy': '~99%',
            'recommended_for': 'Production - tá»‘t cho má»i kÃ­ch thÆ°á»›c dataset'
        })
    
    # 5. LÆ°u indexes info
    info_file = os.path.join(output_dir, 'indexes_info.json')
    with open(info_file, 'w', encoding='utf-8') as f:
        json.dump(indexes_info, f, ensure_ascii=False, indent=2)
    
    print("\n" + "=" * 70)
    print("ğŸ“Š Tá»”NG Káº¾T")
    print("=" * 70)
    print(f"ÄÃ£ táº¡o {len(indexes_info)} FAISS indexes:")
    for i, info in enumerate(indexes_info, 1):
        print(f"\n{i}. {info['type']}")
        print(f"   - File: {info['file']}")
        print(f"   - Speed: {info['speed']}")
        print(f"   - Accuracy: {info['accuracy']}")
        print(f"   - Recommended: {info['recommended_for']}")
    
    print("\n" + "=" * 70)
    print("âœ¨ HOÃ€N THÃ€NH!")
    print("=" * 70)
    
    return indexes_info

def benchmark_indexes(features_dir: str = './features',
                     indexes_dir: str = './faiss_indexes',
                     n_queries: int = 100,
                     k: int = 10):
    """
    So sÃ¡nh hiá»‡u suáº¥t cá»§a cÃ¡c indexes
    
    Args:
        features_dir: ThÆ° má»¥c chá»©a features
        indexes_dir: ThÆ° má»¥c chá»©a indexes
        n_queries: Sá»‘ lÆ°á»£ng queries Ä‘á»ƒ test
        k: Sá»‘ káº¿t quáº£ tráº£ vá»
    """
    print("\n" + "=" * 70)
    print("âš¡ BENCHMARK FAISS INDEXES")
    print("=" * 70)
    
    # Load features
    features_file = os.path.join(features_dir, 'features.npy')
    features = np.load(features_file)
    
    # Chá»n random queries
    np.random.seed(42)
    query_indices = np.random.choice(len(features), n_queries, replace=False)
    queries = features[query_indices]
    
    # Load indexes info
    info_file = os.path.join(indexes_dir, 'indexes_info.json')
    with open(info_file, 'r') as f:
        indexes_info = json.load(f)
    
    results = []
    
    for info in indexes_info:
        print(f"\nğŸ” Testing {info['type']}...")
        
        # Load index
        manager = FAISSIndexManager(features.shape[1])
        manager.load_index(info['file'])
        
        # Benchmark
        start_time = time.time()
        
        for query in queries:
            distances, indices = manager.search(query, k=k)
        
        elapsed = time.time() - start_time
        avg_time = elapsed / n_queries * 1000  # ms
        qps = n_queries / elapsed  # queries per second
        
        result = {
            'type': info['type'],
            'total_time': f"{elapsed:.2f}s",
            'avg_query_time': f"{avg_time:.2f}ms",
            'qps': f"{qps:.2f}",
            'accuracy': info['accuracy']
        }
        results.append(result)
        
        print(f"   - Total time: {elapsed:.2f}s")
        print(f"   - Avg query time: {avg_time:.2f}ms")
        print(f"   - QPS: {qps:.2f}")
    
    # In báº£ng so sÃ¡nh
    print("\n" + "=" * 70)
    print("ğŸ“Š SO SÃNH HIá»†U SUáº¤T")
    print("=" * 70)
    print(f"{'Index Type':<20} {'Avg Time':<12} {'QPS':<10} {'Accuracy':<10}")
    print("-" * 70)
    
    for r in results:
        print(f"{r['type']:<20} {r['avg_query_time']:<12} {r['qps']:<10} {r['accuracy']:<10}")
    
    print("\nğŸ’¡ Gá»£i Ã½:")
    print("   - IndexFlatL2: DÃ¹ng cho demo/test nhá»")
    print("   - IndexIVFFlat: DÃ¹ng khi cáº§n cÃ¢n báº±ng tá»‘c Ä‘á»™/Ä‘á»™ chÃ­nh xÃ¡c")
    print("   - IndexHNSWFlat: Khuyáº¿n nghá»‹ cho production (nhanh + chÃ­nh xÃ¡c)")
    
    return results

def main():
    """
    Main function
    """
    # 1. XÃ¢y dá»±ng indexes
    print("\nğŸš€ Báº¯t Ä‘áº§u xÃ¢y dá»±ng FAISS indexes...\n")
    
    indexes_info = build_faiss_indexes(
        features_dir='./features',
        output_dir='./faiss_indexes',
        build_all=True  # XÃ¢y dá»±ng táº¥t cáº£ loáº¡i index
    )
    
    # 2. Benchmark
    print("\n\nğŸ”¬ Báº¯t Ä‘áº§u benchmark...\n")
    
    benchmark_results = benchmark_indexes(
        features_dir='./features',
        indexes_dir='./faiss_indexes',
        n_queries=100,
        k=10
    )
    
    print("\nâœ¨ HoÃ n thÃ nh táº¥t cáº£!")

if __name__ == "__main__":
    main()